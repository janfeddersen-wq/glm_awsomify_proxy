# Cerebras API Keys Configuration
# Copy this file to .env and replace with your actual API keys
#
# Format: JSON object with key names and API keys
# The proxy will rotate through these keys intelligently:
# - Uses one key until it hits rate limits (429)
# - Automatically switches to next available key
# - Waits and retries if all keys are rate-limited
#
CEREBRAS_API_KEYS={"key1":"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx","key2":"sk-yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy","key3":"sk-zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz"}

# Optional: Cooldown period in seconds after rate limiting (default: 60)
# CEREBRAS_COOLDOWN=60

# Request/Response Logging Configuration
# Enable or disable request/response logging (default: true)
LOG_REQUESTS=true

# Directory to save request/response logs (default: ./logs for local, /app/logs for Docker)
# Logs are organized by date in subdirectories
# LOG_DIR=./logs

# Incoming API Key Authentication
# Enable incoming API key verification (default: false)
# When enabled, clients must provide valid API keys managed via SQLite database
ENABLE_INCOMING_AUTH=false

# SQLite database path for incoming API keys (default: ./data/incoming_keys.db for local, /app/data/incoming_keys.db for Docker)
# Use manage_keys.py CLI tool to add/revoke/list API keys
# INCOMING_KEY_DB=./data/incoming_keys.db

# Alternative API Configuration for Large Requests
# Requests with message content >120k tokens (~480k characters) are routed to these APIs
# Token estimation: 1 token â‰ˆ 4 characters

# Synthetic API Key (primary for large requests)
# Model used: hf:zai-org/GLM-4.6
# SYNTHETIC_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Z.ai API Key (fallback for large requests)
# Model used: glm-4.6
# ZAI_API_KEY=sk-yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy

# Fallback to Alternative APIs on Cerebras Cooldown
# When all Cerebras keys are rate-limited, route to Synthetic/Z.ai instead of waiting (default: false)
# Requires SYNTHETIC_API_KEY and/or ZAI_API_KEY to be configured
# FALLBACK_ON_COOLDOWN=true
